# ============================================
# Knowledge Fusion Module Configuration
# ============================================
# Copy this file to .env and replace placeholder values with your actual credentials
# Windows: copy env.template .env
# Linux/Mac: cp env.template .env

# ============================================
# Neo4j Database Configuration
# ============================================
# Neo4j connection URI (default: bolt://localhost:7687)
NEO4J_URI=bolt://localhost:7687

# Neo4j username (optional if using cred.json)
# NEO4J_USERNAME=neo4j

# Neo4j password (optional if using cred.json)
# NEO4J_PASSWORD=your_neo4j_password_here

# ============================================
# OpenAI LLM Configuration
# ============================================
# REQUIRED: Get your API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-your-openai-api-key-here

# LLM Provider (options: openai, ollama, anthropic)
LLM_PROVIDER=openai

# LLM Model name
# For OpenAI: gpt-3.5-turbo, gpt-4, gpt-4-turbo-preview
# For Ollama: llama2, mistral, etc. (local models)
LLM_MODEL=gpt-3.5-turbo

# Temperature for LLM generation (0.0 to 2.0)
# Lower = more focused, Higher = more creative
LLM_TEMPERATURE=0.3

# Maximum tokens in LLM response
LLM_MAX_TOKENS=1000

# ============================================
# Alternative LLM Providers (Optional)
# ============================================
# If using Anthropic Claude instead of OpenAI
# ANTHROPIC_API_KEY=sk-ant-your-anthropic-api-key-here

# If using Ollama (local models), no API key needed
# Just ensure Ollama is running locally

# ============================================
# Embedding Model Configuration (Optional)
# ============================================
# Embedding model name (default: sentence-transformers/all-MiniLM-L6-v2)
# EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2

# Device for embedding model (cpu or cuda)
# EMBEDDING_DEVICE=cpu

# Batch size for embedding generation
# EMBEDDING_BATCH_SIZE=32

# ============================================
# Retrieval Configuration (Optional)
# ============================================
# Weight for graph retrieval in hybrid mode (0.0 to 1.0)
# RETRIEVAL_GRAPH_WEIGHT=0.7

# Weight for vector retrieval in hybrid mode (0.0 to 1.0)
# RETRIEVAL_VECTOR_WEIGHT=0.3

# Number of top results from graph retrieval
# RETRIEVAL_TOP_K_GRAPH=10

# Number of top results from vector retrieval
# RETRIEVAL_TOP_K_VECTOR=10

# Minimum similarity threshold for vector search (0.0 to 1.0)
# RETRIEVAL_SIMILARITY_THRESHOLD=0.6

# ============================================
# Vector Index Configuration (Optional)
# ============================================
# Name of vector index in Neo4j
# VECTOR_INDEX_NAME=mitre_techniques

# ============================================
# Cache Configuration (Optional)
# ============================================
# Enable embedding cache
# CACHE_ENABLED=true

# Cache directory path
# CACHE_DIR=.cache/knowledge_fusion

# ============================================
# Usage Instructions
# ============================================
# 1. Copy this file: copy env.template .env (Windows) or cp env.template .env (Linux/Mac)
# 2. Open .env file and replace placeholder values:
#    - OPENAI_API_KEY: Replace with your actual OpenAI API key
#    - NEO4J_PASSWORD: Replace if not using cred.json
# 3. Save the file
# 4. The module will automatically load these variables when you run it



